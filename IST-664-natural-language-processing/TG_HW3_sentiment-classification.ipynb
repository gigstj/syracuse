{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"4.5\">\n",
    "\n",
    "In previous work, I have practiced natural language processing techniques on the book Moby Dick by Herman Melville. In this project, I will continue to build on my NLP work by performing sentiment classification on Moby Dick.\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4.5\">\n",
    "\n",
    "I will start off by importing some necessary packages and then importing the data via the nltk gutenberg corpus.\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas\n",
    "import nltk\n",
    "import textblob\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "mobydick = nltk.corpus.gutenberg.raw(\"melville-moby_dick.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"4.5\">\n",
    "\n",
    "Since the text starts off in a raw form, it will need to be processed. In this task, I will be doing sentiment analysis at the sentence level. Therefore, I will use the nltk sentence tokenizer to break the text down into sentences. In the following code, I will use the nltk sent_tokenize function and print out how many sentences there are.\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break the text down into sentences\n",
    "sentences = nltk.sent_tokenize(mobydick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9852\n"
     ]
    }
   ],
   "source": [
    "# How many sentences are there?\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"4.5\">\n",
    "\n",
    "After breaking the text down into sentences, we see that Moby Dick has 9,852 sentences. Next, I will use the textblob package to assign sentiment labels to each sentence. What textblob does is it will assign a polarity score between -1 and 1. Based on that polarity score, I will determine whether the sentence is negative, neutral, or positive. If the polarity score is < 0, then the sentiment will be negative. If the polarity score is = 0, then the sentiment will be neutral. And if the polarity score is > 0, then the sentiment will be posiitve.\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polarity scores for the sentences\n",
    "polarities = [textblob.TextBlob(sent).sentiment.polarity for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for discretizing the polarity scores\n",
    "def getsentiment(polarityscore):\n",
    "    if polarityscore < 0: return \"negative\"\n",
    "    elif polarityscore == 0: return \"neutral\"\n",
    "    else: return \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the polarity scores into sentiment labels\n",
    "sentiments = [getsentiment(polarity) for polarity in polarities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     4197\n",
       "positive    3637\n",
       "negative    2018\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the counts of each label?\n",
    "pandas.DataFrame(sentiments).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"4.5\">\n",
    "\n",
    "Now I will analyze the results by looking at the top 50 adjective phrases, adverb phrases, and verb phrases for the positive and negative categories. The top positive will consist of the sentences with the highest polarities, and the phrases in those sentences. The top negative will consist of the sentences with the lowest polarities, and the phrases in those sentences.\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the sentences, the polarities, and the sentiments\n",
    "sentimentdf = pandas.DataFrame(list(zip(sentences, polarities, sentiments)), columns = [\"Sentence\", \"Polarity\", \"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grammar for an adjective phrase\n",
    "adjp_grammar = \"\"\"\n",
    "ADJP: {<JJ><NN>}\n",
    "      {<NN><JJ>}\n",
    "\"\"\"\n",
    "\n",
    "# Define the grammar for an adverb phrase\n",
    "advp_grammar = \"\"\"\n",
    "ADVP: {<RB><V>}\n",
    "      {<RB><NN>}\n",
    "      {<RB><JJ>}\n",
    "\"\"\"\n",
    "\n",
    "# Define the grammar for an verb phrase\n",
    "vp_grammar = \"\"\"\n",
    "VP: {<VBP><DT><NN>}\n",
    "    {<VBN><DT><NN>}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for retrieving phrases\n",
    "def get_phrase(sentence, pattern, phrase):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    parser = nltk.RegexpParser(pattern)\n",
    "    tree = parser.parse(tags)\n",
    "    for sub1 in tree.subtrees():\n",
    "        for sub2 in sub1:\n",
    "            if type(sub2) != tuple:\n",
    "                extract = \"\"\n",
    "                for sub3 in sub2.leaves():\n",
    "                    extract += \" \" + str(sub3[0])\n",
    "                return extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the sentences and retrieve the adj phrases\n",
    "adj_phrases = []\n",
    "adv_phrases = []\n",
    "v_phrases = []\n",
    "for sentence in sentences:\n",
    "    try:\n",
    "        adj_phrase = get_phrase(sentence, adjp_grammar, \"ADJP\")\n",
    "        adv_phrase = get_phrase(sentence, advp_grammar, \"ADVP\")\n",
    "        v_phrase = get_phrase(sentence, vp_grammar, \"VP\")\n",
    "        adj_phrases.append(adj_phrase)\n",
    "        adv_phrases.append(adv_phrase)\n",
    "        v_phrases.append(v_phrase)\n",
    "    except:\n",
    "        adj_phrases.append(None)\n",
    "        adv_phrases.append(None)\n",
    "        v_phrases.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together a dataframe of the sentence, phrase, and test\n",
    "mobydf = pandas.DataFrame(list(zip(\n",
    "    sentences,\n",
    "    polarities,\n",
    "    sentiments,\n",
    "    adj_phrases,\n",
    "    adv_phrases,\n",
    "    v_phrases)),\n",
    "    columns = [\n",
    "        \"Sentence\",\n",
    "        \"Polarity\",\n",
    "        \"Sentiment\",\n",
    "        \"AdjPhrase\",\n",
    "        \"AdvPhrase\",\n",
    "        \"VPhrase\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " give the glory\n",
      " crush the quadrant\n",
      " make a spread\n",
      " go the gait\n",
      " been a sprat\n",
      " see this whale-steak\n",
      " offer this cup\n",
      " seen a bird\n",
      " granted the ship\n",
      " mean a downright\n",
      " worsted all round\n",
      " mend the matter\n",
      " wrenched the ship\n",
      " know some o\n",
      " round the socket\n",
      " get a chance\n",
      " turned the round\n",
      " know the proverb\n",
      " trace the round\n",
      " have the heart\n",
      " killed some distance\n",
      " Have an eye\n",
      " remain a part\n",
      " broken a finger\n",
      " vertebra the bottom\n",
      " cleared the foul\n",
      " been a whale-boat\n",
      " make a point\n",
      " robbed a widow\n",
      " differ the sea\n",
      " nigh the beach\n",
      " are the moody\n",
      " behold an oarsman\n",
      " known any profound\n",
      " seem the connecting\n",
      " round the waist\n",
      " say the word\n",
      " have no objection\n",
      " been the case\n",
      " been a pirate\n",
      " are an advance\n",
      " found some salvation\n",
      " are a plenty\n",
      " been a mortar\n",
      " heaven a murderer\n",
      " furnished a proverb\n",
      " reckon a monster\n",
      " provided a system\n",
      " home the oil\n",
      " round the world\n"
     ]
    }
   ],
   "source": [
    "# Print out the top 50 adjective phrases for positive\n",
    "mobytemp = mobydf[mobydf.Sentiment == \"negative\"].sort_values(by = \"Polarity\", ascending = True, axis = 0)\n",
    "counter = 0\n",
    "for phrase in list(mobytemp[\"VPhrase\"]):\n",
    "    if counter >= 50:\n",
    "        break\n",
    "    if phrase:\n",
    "        print(phrase)\n",
    "        counter += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "837a5e7ae28b4e198c1d8cf4796a058d56e0b65e3e1483208ccae61f9a209f4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
