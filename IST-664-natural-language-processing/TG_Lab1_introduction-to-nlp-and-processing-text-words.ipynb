{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load libraries #####\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib as plot\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View books from the Gutenberg project\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the name of the first book into a variable\n",
    "file0 = nltk.corpus.gutenberg.fileids()[0]\n",
    "print(file0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887071\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Store the text from the book into a variable\n",
    "emmatext = nltk.corpus.gutenberg.raw(file0)\n",
    "print(len(emmatext))\n",
    "print(type(emmatext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nan'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first 120 characters\n",
    "emmatext[:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191785"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the standard tokenizer that comes with NLTK\n",
    "emmatokens = nltk.word_tokenize(emmatext)\n",
    "print(len(emmatokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with']\n"
     ]
    }
   ],
   "source": [
    "# Look at the first 50 tokens\n",
    "print(emmatokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets standardize all the words to lowercase\n",
    "emmawords = [w.lower() for w in emmatokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '&', \"'\", \"''\", \"'d\", \"'s\", \"'t\", \"'ye\", '(', ')', ',', '--', '.', '10,000', '1816', '23rd', '24th', '26th', '28th', '7th', '8th', ':', ';', '?', '[', ']', '_______', '_a_', '_accepted_', '_adair_', '_addition_', '_all_', '_almost_', '_alone_', '_amor_', '_and_', '_answer_', '_any_', '_appropriation_', '_as_', '_assistance_', '_at_', '_bath_', '_be_', '_been_', '_blunder_', '_boiled_', '_both_', '_bride_', '_broke_']\n"
     ]
    }
   ],
   "source": [
    "# Create a unique list of words using a set\n",
    "emmavocab = sorted(set(emmawords))\n",
    "print(emmavocab[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check occurneces of the word emma in the text\n",
    "emmawords.count(\"emma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a frequency distribution of the words\n",
    "fdist = nltk.FreqDist(emmawords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'woodhouse', ',', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'existence', ';', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'world', 'very', 'little', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'youngest', 'two']\n"
     ]
    }
   ],
   "source": [
    "# Look at the keys of the frequency distribution\n",
    "fdistkeys = list(fdist.keys())\n",
    "print(fdistkeys[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look up a key\n",
    "fdist[\"emma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top keys\n",
    "topkeys = fdist.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(',', 12016)\n",
      "('.', 6355)\n",
      "('the', 5201)\n",
      "('to', 5181)\n",
      "('and', 4877)\n",
      "('of', 4284)\n",
      "('i', 3177)\n",
      "('a', 3124)\n",
      "('--', 3100)\n",
      "('it', 2503)\n",
      "(\"''\", 2452)\n",
      "('her', 2448)\n",
      "('was', 2396)\n",
      "(';', 2353)\n",
      "('she', 2336)\n",
      "('not', 2281)\n",
      "('in', 2173)\n",
      "('be', 1970)\n",
      "('you', 1967)\n",
      "('he', 1806)\n",
      "('that', 1805)\n",
      "('``', 1735)\n",
      "('had', 1623)\n",
      "('but', 1441)\n",
      "('as', 1436)\n",
      "('for', 1346)\n",
      "('have', 1320)\n",
      "('is', 1241)\n",
      "('with', 1215)\n",
      "('very', 1202)\n",
      "('his', 1141)\n",
      "('mr.', 1091)\n",
      "('!', 1063)\n",
      "('at', 1030)\n",
      "('so', 968)\n",
      "(\"'s\", 866)\n",
      "('emma', 855)\n",
      "('all', 841)\n",
      "('could', 836)\n",
      "('would', 818)\n"
     ]
    }
   ],
   "source": [
    "# Loop over each pair of keys and print it\n",
    "for pair in topkeys:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(',', 0.06265349219177725)\n",
      "('.', 0.03313606382146675)\n",
      "('the', 0.027118909195192532)\n",
      "('to', 0.0270146257527961)\n",
      "('and', 0.02542951742837031)\n",
      "('of', 0.022337513361316057)\n",
      "('i', 0.016565424824673464)\n",
      "('a', 0.016289073702322913)\n",
      "('--', 0.016163933571447194)\n",
      "('it', 0.013051072815913653)\n",
      "(\"''\", 0.012785150037802747)\n",
      "('her', 0.012764293349323462)\n",
      "('was', 0.012493156399092735)\n",
      "(';', 0.012268946997940402)\n",
      "('she', 0.012180306071903433)\n",
      "('not', 0.011893526605313242)\n",
      "('in', 0.0113303960163725)\n",
      "('be', 0.010271919076048701)\n",
      "('you', 0.010256276559689236)\n",
      "('he', 0.009416794848397945)\n",
      "('that', 0.009411580676278125)\n",
      "('``', 0.009046588627890607)\n",
      "('had', 0.00846260135047058)\n",
      "('but', 0.007513622024663034)\n",
      "('as', 0.007487551164063926)\n",
      "('for', 0.007018275673279975)\n",
      "('have', 0.0068827071981646115)\n",
      "('is', 0.006470787600698699)\n",
      "('with', 0.006335219125583336)\n",
      "('very', 0.0062674348880256536)\n",
      "('his', 0.005949370388716532)\n",
      "('mr.', 0.005688661782725448)\n",
      "('!', 0.005542664963370441)\n",
      "('at', 0.0053705972834163255)\n",
      "('so', 0.005047318611987382)\n",
      "(\"'s\", 0.004515473055765571)\n",
      "('emma', 0.004458117162447532)\n",
      "('all', 0.004385118752770029)\n",
      "('could', 0.004359047892170921)\n",
      "('would', 0.004265192794014131)\n"
     ]
    }
   ],
   "source": [
    "# Convert frequencies to percentage of totals for the top keys\n",
    "topkeysnorm = [(word, freq / len(emmawords)) for (word, freq) in topkeys]\n",
    "for pair in topkeysnorm:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(',', 7024)\n",
      "('the', 3328)\n",
      "('.', 3119)\n",
      "('and', 2786)\n",
      "('to', 2782)\n",
      "('of', 2568)\n",
      "('a', 1592)\n",
      "('in', 1383)\n",
      "('was', 1337)\n",
      "(';', 1319)\n",
      "('her', 1203)\n",
      "('had', 1186)\n",
      "('she', 1146)\n",
      "('i', 1123)\n",
      "('it', 1038)\n",
      "('not', 976)\n",
      "('he', 961)\n",
      "('be', 950)\n",
      "(\"''\", 912)\n",
      "('that', 882)\n",
      "('as', 809)\n",
      "('for', 707)\n",
      "('but', 664)\n",
      "('his', 659)\n",
      "('with', 654)\n",
      "('``', 652)\n",
      "('you', 628)\n",
      "('have', 589)\n",
      "('at', 533)\n",
      "('all', 530)\n"
     ]
    }
   ],
   "source": [
    "##### Repeat the steps with a different book #####\n",
    "\n",
    "# Store the name of the first book into a variable\n",
    "file1 = nltk.corpus.gutenberg.fileids()[1]\n",
    "\n",
    "# Store the text from the book into a variable\n",
    "austenptext = nltk.corpus.gutenberg.raw(file1)\n",
    "\n",
    "# Use the standard tokenizer that comes with NLTK\n",
    "austenptokens = nltk.word_tokenize(austenptext)\n",
    "\n",
    "# Lets standardize all the words to lowercase\n",
    "austenpwords = [w.lower() for w in austenptokens]\n",
    "\n",
    "# Create a frequency distribution of the words\n",
    "fdist = nltk.FreqDist(austenpwords)\n",
    "\n",
    "# Get the top 30 words\n",
    "topkeys = fdist.most_common(30)\n",
    "\n",
    "# Print out the word frequency pairs\n",
    "for pair in topkeys:\n",
    "    print(pair)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "837a5e7ae28b4e198c1d8cf4796a058d56e0b65e3e1483208ccae61f9a209f4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
