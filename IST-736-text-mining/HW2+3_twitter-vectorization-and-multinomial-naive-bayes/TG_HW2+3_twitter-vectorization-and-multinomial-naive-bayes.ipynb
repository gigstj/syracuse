{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "Hello and welcome to my report for homework assignment 2+3 in IST 736 Text\n",
    "Mining. For this analysis, I decided to use a new dataset instead of the dataset\n",
    "from the first assignment. This is because in the first assignment, I had\n",
    "already done most of the steps that are required for this assignment including\n",
    "vectorization and implementing the multinomial naive bayes model.\n",
    "\n",
    "I am excited about the new dataset because it is a dataset that I will be\n",
    "collecting myself. The data that I will be collecting will consist of a sample\n",
    "of NFL football related data. I will be collecting actual fantasy points and\n",
    "projected fantasy points of starting offensive players in week 7, along with a\n",
    "corpus of tweets related to those players. I will then be exploring the tweets\n",
    "and applying machine learning.\n",
    "\n",
    "The objective is to see if information from tweets can be used to predict whether\n",
    "or not a player will outperform their projections for a given week.\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "### **Data Collection**\n",
    "\n",
    "The data collection process was done in R because I was unable to figure out how\n",
    "to do it in Python. I will be providing a copy of the R markdown file that goes\n",
    "through the data collection process. The results from running the R code might be\n",
    "different though because the tweets will be different. I will also be providing a\n",
    "copy of the data being used in this report in a csv file.\n",
    "\n",
    "I will summarize the data that I collected. I started off by retrieving the starting\n",
    "rosters for week 7 NFL. I created a list of the players only from the QB, RB, WR, and\n",
    "TE positions. I then collected each of these players projected fantasy points for\n",
    "week 7. Unfortuantely I was not able to find a specific week 7 projection so I ended up\n",
    "taking their season total projection and dividing it by the number of games. The oucome\n",
    "variable is the variable that I am trying to predict in this report. 0 means the player\n",
    "underperformed to their projection (less than 0.5 * projection), 1 means that they\n",
    "were in line with thei projection (between 0.5 to 1.5 * projection) and 2 means that the\n",
    "player outperformed their projection (greater than 1.5 * projection). Lastly, I scraped\n",
    "100 tweets for each of the players using the player name as the key word in the search.\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "#### **Import Libraries**\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "I will start off by loading some ofthe necessary packages. A short description of what I am using each package for is provided. For more information about the packages please look them up on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "\n",
    "import numpy as np         # Working with numbers\n",
    "import pandas as pd        # Working with dataframes\n",
    "import matplotlib as plt   # Plotting\n",
    "import tweepy              # Use the Twitter API\n",
    "import re                  # Regular expression\n",
    "import nltk                # Natural language tool kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "#### **Import Data**\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "I will load the data that I will be using for this analysis. As mentioned in the introduction, I have already collected this data in R and exported it to a csv format. The cleaning, stemming, and removing of stopwords has already been done. Here is a summary of the reduction of the vocabulary size from the corpus.\n",
    "\n",
    "- original vocabulary = 146,224 words and 16,099 unique words\n",
    "- all lowercase = 146,224 words and 14,185 unique words\n",
    "- removed usernames = 142,606 words and 12,241 unique words\n",
    "- removed http links = 141,203 words and 10,921 unique words\n",
    "- removed punctuation tokens = 99,295 words and 9,368 unique words\n",
    "- removed stopwords = 52.490 words and 8,988 unique words\n",
    "- stemmed = 52,490 words and 7,632 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "tweetsdf = pd.read_csv(\"tweets.csv\")\n",
    "tweets = tweetsdf[\"tweets\"]\n",
    "outcomes = tweetsdf[\"outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    67\n",
       "2    44\n",
       "0    37\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of the labels\n",
    "\n",
    "outcomes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "#### **Vectorize**\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "In the next section, I will be performing the necessary data preprocessing steps\n",
    "to get the data in a form that can be used for machine learning. I will be doing\n",
    "four different types of vectorization - boolean, count, relative, and tfidf. I am\n",
    "not sure which one will be the best for the machine learning model so I would like\n",
    "to try all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a function for vectorizing\n",
    "def vectorize(tweets, labels, method):\n",
    "  \n",
    "  # Choose the vectorizer based on the method arg\n",
    "  if method == \"bool\":\n",
    "    vectorizer = TfidfVectorizer(binary = True)\n",
    "  if method == \"count\":\n",
    "    vectorizer = CountVectorizer()\n",
    "  if method == \"relative\":\n",
    "    vectorizer = TfidfVectorizer(use_idf = False, norm = \"l1\")\n",
    "  # if method == \"tfidf\":\n",
    "    # vectorizer == TfidfVectorizer()\n",
    "  \n",
    "  # Do the vectorization\n",
    "  vectors = vectorizer.fit_transform(tweets)\n",
    "  \n",
    "  # Store the feature names\n",
    "  features = vectorizer.get_feature_names()\n",
    "  \n",
    "  # Put it into a dataframe\n",
    "  vectors_df = pd.DataFrame(vectors.toarray(), columns = features)\n",
    "  \n",
    "  # Add the outcomes\n",
    "  vectors_df[\"outcomes\"] = labels\n",
    "  \n",
    "  # Return the dataframe\n",
    "  return vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the vectorization\n",
    "\n",
    "tweets_bool = vectorize(tweets, outcomes, \"bool\")\n",
    "tweets_count = vectorize(tweets, outcomes, \"count\")\n",
    "tweets_rel = vectorize(tweets, outcomes, \"relative\")\n",
    "# tweets_tfidf = vectorize(tweets, outcomes, \"tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p>&nbsp;</p>\n",
    "\n",
    "#### **Multinomial Naive Bayes Model**\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "Finally, the data is preprocessed and ready to be used in a machine\n",
    "learning model. The model of choice in this assignment will be the\n",
    "multinomial naive bayes model. I will be using a 5 fold cross validation\n",
    "to evaluate the performance of the model and I will do this on each\n",
    "of the vectorization options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a function to train models\n",
    "\n",
    "def trainer(train_predictors, train_labels, test_predictors, test_labels):\n",
    "  bayes = MultinomialNB()\n",
    "  bayes.fit(train_predictors, train_labels)\n",
    "  print(\"Training Accuracy = \", bayes.score(train_predictors, train_labels))\n",
    "  test_predictions = bayes.predict(test_predictors)\n",
    "  print(\"Testing Accuracy = \", accuracy_score(test_labels, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define a function to run the model with 5 fold cv\n",
    "\n",
    "def run_model(data, num_folds):\n",
    "\n",
    "  split = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = 42)\n",
    "\n",
    "  for train_index, test_index in split.split(data, data[\"outcomes\"]):\n",
    "    \n",
    "    train_data = data.loc[train_index, :]\n",
    "    test_data = data.loc[test_index, :]\n",
    "    \n",
    "    train_predictors = train_data.drop(\"outcomes\", axis = 1)\n",
    "    test_predictors = test_data.drop(\"outcomes\", axis = 1)\n",
    "    \n",
    "    train_labels = train_data[\"outcomes\"].copy()\n",
    "    test_labels = test_data[\"outcomes\"].copy()\n",
    "    \n",
    "    trainer(train_predictors, train_labels, test_predictors, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.5\n",
      "Testing Accuracy =  0.4666666666666667\n",
      "Training Accuracy =  0.5\n",
      "Testing Accuracy =  0.4666666666666667\n",
      "Training Accuracy =  0.5\n",
      "Testing Accuracy =  0.4666666666666667\n",
      "Training Accuracy =  0.5042016806722689\n",
      "Testing Accuracy =  0.4482758620689655\n",
      "Training Accuracy =  0.5210084033613446\n",
      "Testing Accuracy =  0.4482758620689655\n",
      "\n",
      "\n",
      "Training Accuracy =  0.9491525423728814\n",
      "Testing Accuracy =  0.43333333333333335\n",
      "Training Accuracy =  0.9491525423728814\n",
      "Testing Accuracy =  0.4\n",
      "Training Accuracy =  0.9661016949152542\n",
      "Testing Accuracy =  0.5333333333333333\n",
      "Training Accuracy =  0.9495798319327731\n",
      "Testing Accuracy =  0.4827586206896552\n",
      "Training Accuracy =  0.9327731092436975\n",
      "Testing Accuracy =  0.5172413793103449\n",
      "\n",
      "\n",
      "Training Accuracy =  0.4576271186440678\n",
      "Testing Accuracy =  0.43333333333333335\n",
      "Training Accuracy =  0.4491525423728814\n",
      "Testing Accuracy =  0.4666666666666667\n",
      "Training Accuracy =  0.4491525423728814\n",
      "Testing Accuracy =  0.4666666666666667\n",
      "Training Accuracy =  0.453781512605042\n",
      "Testing Accuracy =  0.4482758620689655\n",
      "Training Accuracy =  0.453781512605042\n",
      "Testing Accuracy =  0.4482758620689655\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the model on the 3 different vectorization options\n",
    "\n",
    "for dataframe in [tweets_bool, tweets_count, tweets_rel]:\n",
    "    run_model(num_folds = 5, data = dataframe)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p>&nbsp;</p>\n",
    "\n",
    "#### **Top Features**\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "Based on the results of the naive bayes models, it looks like the\n",
    "relative frequency vectorization produced the best results. There\n",
    "were signs of overtraining in both the boolean and the count\n",
    "vectorizations because the the training accuracy was much higher\n",
    "than the test accuracy.\n",
    "\n",
    "I will recreate the bayes model on the relative frequency vectorized\n",
    "data now, and then I will evaluate the top features that the model\n",
    "learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf = False, norm = \"l1\")\n",
    "vectors = vectorizer.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the predictors and the labels\n",
    "\n",
    "predictors = tweets_rel.drop(\"outcomes\", axis = 1)\n",
    "labels = tweets_rel[\"outcomes\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the multinomial naive bayes model\n",
    "\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(predictors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-9.179608495084489, 'would'), (-9.145613669478841, 'get'), (-9.140887570746374, 'like'), (-9.135357730357507, 'yard'), (-9.106924202870706, 'game'), (-9.09214598726425, 'wr'), (-9.08986564529752, 'te'), (-9.06491979033236, 'play'), (-9.046515207487195, 'start'), (-8.911387845282169, 'week')]\n"
     ]
    }
   ],
   "source": [
    "# Look at what it learned for above performance players\n",
    "\n",
    "feature_ranks = sorted(zip(bayes.feature_log_prob_[2], vectorizer.get_feature_names()))\n",
    "very_negative_features = feature_ranks[-10:]\n",
    "print(very_negative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-9.04746024845629, 'team'), (-9.037476467576205, 'qb'), (-9.0016298443785, 'get'), (-8.991921310219187, 'trade'), (-8.991539082984701, 'wr'), (-8.9669189850458, 'like'), (-8.928664278962128, 'game'), (-8.920223121855248, 'start'), (-8.912716913254654, 'play'), (-8.760562178194458, 'week')]\n"
     ]
    }
   ],
   "source": [
    "# Look at what it learned for inline performance players\n",
    "\n",
    "feature_ranks = sorted(zip(bayes.feature_log_prob_[1], vectorizer.get_feature_names()))\n",
    "very_negative_features = feature_ranks[-10:]\n",
    "print(very_negative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-9.209476855875122, 'team'), (-9.206107867882043, 'te'), (-9.205950152646302, 'start'), (-9.202518313884752, 'like'), (-9.172651391730648, 'trade'), (-9.141575613858626, 'game'), (-9.123913153003343, 'play'), (-9.1207833888909, 'get'), (-9.067070069233766, 'wr'), (-9.055899064998462, 'week')]\n"
     ]
    }
   ],
   "source": [
    "# Look at what it learned for below performance players\n",
    "\n",
    "feature_ranks = sorted(zip(bayes.feature_log_prob_[0], vectorizer.get_feature_names()))\n",
    "very_negative_features = feature_ranks[-10:]\n",
    "print(very_negative_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "The models did not perform as highly as I would have liked them to, so I am\n",
    "unable to conclude in this analysis if the tweets were meaningful in determing\n",
    "how a player performed in the game. All of the models seemed to be in about\n",
    "the 40% - 50% accuracy range, while the majority vote baseline would be about\n",
    "45% by just picking the outcome to be 1.\n",
    "\n",
    "Looking at the top features, it looks like a lot of the same words were picked\n",
    "up on by the model for the different classes which likely caused confusion and\n",
    "noise in the model. It does not appear that the models have uncovered anything\n",
    "insightful. It is possible that I could have done a better job with the data\n",
    "cleaning, but due to time constraints I was unable to do so.\n",
    "\n",
    "I believe that a major reason for this was the limitations that I faced during\n",
    "the data collection process. First, the tweets that I collected were already\n",
    "after the time the game had finished because I am unable to specifiy a date range\n",
    "when using the twitter API due to restricted access. Ideally the tweets would\n",
    "be for the week leading up the players game. Second, I was unable to get the players\n",
    "true projection, I had to take an average of their season projection, which is not\n",
    "ideal either because that projection changes every week.\n",
    "\n",
    "In summary, unfortunately this project did not turn out the way that I hoped it would\n",
    "for the amount of time that I spent on it. On a positive note, however, I got to\n",
    "apply all of the concepts that I have learned about in the course, and I was able to get\n",
    "the reticulate package in R working, even though I ended up moving back over to vs code\n",
    "to finish the analysis. Despite the failure, with all else considered, this was\n",
    "a good learning experience for me.\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "#### **References**\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "https://stmorse.github.io/journal/pfr-scrape-python.html  \n",
    "https://www.rstudio.com/resources/webinars/r-python-in-rstudio-1-2-with-reticulate/  \n",
    "https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "837a5e7ae28b4e198c1d8cf4796a058d56e0b65e3e1483208ccae61f9a209f4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
