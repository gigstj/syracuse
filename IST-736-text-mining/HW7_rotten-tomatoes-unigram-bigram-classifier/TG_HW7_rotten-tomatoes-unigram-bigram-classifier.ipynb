{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "# **IST 736 HOMEWORK 7**\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# Import packages from scikit-learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "# **TASK 1 - UNIGRAM VECTORS**\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data_train = pandas.read_csv(\"train.tsv\", delimiter = \"\\t\")\n",
    "data_test = pandas.read_csv(\"test.tsv\", delimiter = \"\\t\")\n",
    "X = data_train.Phrase.copy()\n",
    "y = data_train.Sentiment.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test/train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Balance \n",
      " 2    47985\n",
      "3    19608\n",
      "1    16348\n",
      "4     5448\n",
      "0     4247\n",
      "Name: Sentiment, dtype: int64 \n",
      "\n",
      "Test Class Balance \n",
      " 2    31597\n",
      "3    13319\n",
      "1    10925\n",
      "4     3758\n",
      "0     2825\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the class balances\n",
    "print(\"Train Class Balance\", \"\\n\", y_train.value_counts(), \"\\n\")\n",
    "print(\"Test Class Balance\", \"\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate vectorizer\n",
    "unigram_count_vectorizer = CountVectorizer(\n",
    "\tencoding = \"latin-1\",\n",
    "\tbinary = False,\n",
    "\tmin_df = 5,\n",
    "\tstop_words = \"english\"\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the train data and vectorize the train data\n",
    "X_train_vec = unigram_count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Vectorize the test data\n",
    "X_test_vec = unigram_count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6040625400486992\n"
     ]
    }
   ],
   "source": [
    "# Train a MNB classifier\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_vec, y_train)\n",
    "print(nb_clf.score(X_test_vec,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6218922209406639\n"
     ]
    }
   ],
   "source": [
    "# Train a SVM classifier\n",
    "svm_clf = LinearSVC(C = 1, max_iter = 10000)\n",
    "svm_clf.fit(X_train_vec, y_train)\n",
    "print(svm_clf.score(X_test_vec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for MNB Model \n",
      "\n",
      "[[  703  1291   723    94    14]\n",
      " [  618  4123  5507   628    49]\n",
      " [  228  2417 25570  3168   214]\n",
      " [   32   486  5691  6316   794]\n",
      " [    3    56   703  2000   996]] \n",
      "\n",
      "Confusion Matrix for SVM Model \n",
      "\n",
      "[[  876  1225   633    72    19]\n",
      " [  710  4025  5587   540    63]\n",
      " [  189  2106 26901  2241   160]\n",
      " [   42   420  6131  5674  1052]\n",
      " [    7    45   585  1776  1345]] \n",
      "\n",
      "Difference of SVM and MNB \n",
      "\n",
      "[[ -173    66    90    22    -5]\n",
      " [  -92    98   -80    88   -14]\n",
      " [   39   311 -1331   927    54]\n",
      " [  -10    66  -440   642  -258]\n",
      " [   -4    11   118   224  -349]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix for mnb and svm\n",
    "print(\"Confusion Matrix for MNB Model\", \"\\n\")\n",
    "print(confusion_matrix(y_test, nb_clf.predict(X_test_vec), labels = [0,1,2,3,4]), \"\\n\")\n",
    "print(\"Confusion Matrix for SVM Model\", \"\\n\")\n",
    "print(confusion_matrix(y_test, svm_clf.predict(X_test_vec), labels = [0,1,2,3,4]), \"\\n\")\n",
    "print(\"Difference of SVM and MNB\", \"\\n\")\n",
    "print(confusion_matrix(y_test, nb_clf.predict(X_test_vec), labels = [0,1,2,3,4]) -\n",
    "      confusion_matrix(y_test, svm_clf.predict(X_test_vec), labels = [0,1,2,3,4]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for MNB Model\n",
      "[0.44381313 0.4924161  0.66947688 0.51745043 0.48185776] \n",
      "\n",
      "Recall for MNB Model\n",
      "[0.24884956 0.3773913  0.80925404 0.47420978 0.26503459] \n",
      "\n",
      "Classification Report for MNB Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.25      0.32      2825\n",
      "           1       0.49      0.38      0.43     10925\n",
      "           2       0.67      0.81      0.73     31597\n",
      "           3       0.52      0.47      0.49     13319\n",
      "           4       0.48      0.27      0.34      3758\n",
      "\n",
      "    accuracy                           0.60     62424\n",
      "   macro avg       0.52      0.43      0.46     62424\n",
      "weighted avg       0.58      0.60      0.59     62424\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision, recall, and classification report for mnb\n",
    "print(\"Precision for MNB Model\")\n",
    "print(precision_score(y_test, nb_clf.predict(X_test_vec), average = None), \"\\n\")\n",
    "print(\"Recall for MNB Model\")\n",
    "print(recall_score(y_test, nb_clf.predict(X_test_vec), average = None), \"\\n\")\n",
    "print(\"Classification Report for MNB Model\")\n",
    "print(classification_report(y_test, nb_clf.predict(X_test_vec), target_names = [\"0\",\"1\",\"2\",\"3\",\"4\"]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for SVM Model\n",
      "[0.48026316 0.51464007 0.67527675 0.55071338 0.50966275] \n",
      "\n",
      "Recall for SVM Model\n",
      "[0.3100885  0.36842105 0.8513783  0.42600796 0.35790314] \n",
      "\n",
      "Classification Report for SVM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.31      0.38      2825\n",
      "           1       0.51      0.37      0.43     10925\n",
      "           2       0.68      0.85      0.75     31597\n",
      "           3       0.55      0.43      0.48     13319\n",
      "           4       0.51      0.36      0.42      3758\n",
      "\n",
      "    accuracy                           0.62     62424\n",
      "   macro avg       0.55      0.46      0.49     62424\n",
      "weighted avg       0.60      0.62      0.60     62424\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision, recall, and classification report for svm\n",
    "print(\"Precision for SVM Model\")\n",
    "print(precision_score(y_test, svm_clf.predict(X_test_vec), average = None), \"\\n\")\n",
    "print(\"Recall for SVM Model\")\n",
    "print(recall_score(y_test, svm_clf.predict(X_test_vec), average = None), \"\\n\")\n",
    "print(\"Classification Report for SVM Model\")\n",
    "print(classification_report(y_test, svm_clf.predict(X_test_vec), target_names = [\"0\",\"1\",\"2\",\"3\",\"4\"]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature ranks\n",
    "feature_ranks_very_neg_mnb = sorted(zip(nb_clf.feature_log_prob_[0], unigram_count_vectorizer.get_feature_names()))\n",
    "feature_ranks_very_pos_mnb = sorted(zip(nb_clf.feature_log_prob_[4], unigram_count_vectorizer.get_feature_names()))\n",
    "feature_ranks_very_neg_svm = sorted(zip(svm_clf.coef_[0], unigram_count_vectorizer.get_feature_names()))\n",
    "feature_ranks_very_pos_svm = sorted(zip(svm_clf.coef_[4], unigram_count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Indicative Words for Very Negative Category MNB Model \n",
      "\n",
      "[(-5.998191867857409, 'does'), (-5.998191867857409, 'time'), (-5.987142031670825, 'comedy'), (-5.965402045034418, 'minutes'), (-5.8632725499580385, 'characters'), (-5.615199615601304, 'just'), (-5.204696713463182, 'like'), (-4.873984032000336, 'bad'), (-4.8246782710161815, 'film'), (-4.341022552602119, 'movie')] \n",
      "\n",
      "Top 10 Indicative Words for Very Negative Category SVM Model \n",
      "\n",
      "[(1.5336166732805725, 'awfulness'), (1.5405298274665544, 'dehumanizing'), (1.5433730699417667, 'disappointment'), (1.5758202783829676, 'turd'), (1.6000339723511974, 'worthless'), (1.6015543663565792, 'repulsive'), (1.6573642229516043, 'unappealing'), (1.7640482390775962, 'unbearable'), (1.8708641459657862, 'dud'), (2.0389985608287358, 'unwatchable')]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 very negative for mnb and svm\n",
    "print(\"Top 10 Indicative Words for Very Negative Category MNB Model\", \"\\n\")\n",
    "print(feature_ranks_very_neg_mnb[-10: ], \"\\n\")\n",
    "print(\"Top 10 Indicative Words for Very Negative Category SVM Model\", \"\\n\")\n",
    "print(feature_ranks_very_neg_svm[-10: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Indicative Words for Very Positive Category MNB Model \n",
      "\n",
      "[(-5.822900380967689, 'performance'), (-5.782734339242355, 'great'), (-5.706940499872821, 'performances'), (-5.706940499872821, 'story'), (-5.61628613160469, 'comedy'), (-5.390479462870997, 'good'), (-5.270335151028934, 'funny'), (-5.150457873769435, 'best'), (-4.809810265737742, 'movie'), (-4.286562121973194, 'film')] \n",
      "\n",
      "Top 10 Indicative Words for Very Positive Category SVM Model \n",
      "\n",
      "[(1.5381360711706258, 'glorious'), (1.572364679976549, 'proud'), (1.6261953718029958, 'praiseworthy'), (1.6394560491723595, 'standout'), (1.7019432057944854, 'zings'), (1.7518054155415512, 'luminous'), (1.7856524779850782, 'astoundingly'), (1.8370938031766693, 'perfection'), (1.8922061253831526, 'celebrated'), (1.9519104812622925, 'refreshes')]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 very positive for mnb and svm\n",
    "print(\"Top 10 Indicative Words for Very Positive Category MNB Model\", \"\\n\")\n",
    "print(feature_ranks_very_pos_mnb[-10: ], \"\\n\")\n",
    "print(\"Top 10 Indicative Words for Very Positive Category SVM Model\", \"\\n\")\n",
    "print(feature_ranks_very_pos_svm[-10: ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "# **TASK 2 - UNIGRAM AND BIGRAM VECTORS**\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate vectorizer\n",
    "gram12_count_vectorizer = CountVectorizer(\n",
    "\tencoding = \"latin-1\",\n",
    "    ngram_range = (1,2),\n",
    "\tmin_df = 5,\n",
    "\tstop_words = \"english\"\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the train data and vectorize the train data\n",
    "X_train_vec = gram12_count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Vectorize the test data\n",
    "X_test_vec = gram12_count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5952197872613098\n"
     ]
    }
   ],
   "source": [
    "# Train a MNB classifier\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_vec, y_train)\n",
    "print(nb_clf.score(X_test_vec,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6284441881327695\n"
     ]
    }
   ],
   "source": [
    "# Train a SVM classifier\n",
    "svm_clf = LinearSVC(C = 1, max_iter = 100000)\n",
    "svm_clf.fit(X_train_vec, y_train)\n",
    "print(svm_clf.score(X_test_vec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for MNB Model \n",
      "\n",
      "[[  809  1268   644    89    15]\n",
      " [  814  4404  5038   610    59]\n",
      " [  387  3034 24254  3574   348]\n",
      " [   55   520  5180  6489  1075]\n",
      " [    7    60   592  1899  1200]] \n",
      "\n",
      "Confusion Matrix for SVM Model \n",
      "\n",
      "[[  979  1305   464    61    16]\n",
      " [  857  4535  5012   473    48]\n",
      " [  239  2502 25948  2742   166]\n",
      " [   46   347  5397  6281  1248]\n",
      " [   10    29   444  1788  1487]] \n",
      "\n",
      "Difference of SVM and MNB \n",
      "\n",
      "[[ -170   -37   180    28    -1]\n",
      " [  -43  -131    26   137    11]\n",
      " [  148   532 -1694   832   182]\n",
      " [    9   173  -217   208  -173]\n",
      " [   -3    31   148   111  -287]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix for mnb and svm\n",
    "print(\"Confusion Matrix for MNB Model\", \"\\n\")\n",
    "print(confusion_matrix(y_test, nb_clf.predict(X_test_vec), labels = [0,1,2,3,4]), \"\\n\")\n",
    "print(\"Confusion Matrix for SVM Model\", \"\\n\")\n",
    "print(confusion_matrix(y_test, svm_clf.predict(X_test_vec), labels = [0,1,2,3,4]), \"\\n\")\n",
    "print(\"Difference of SVM and MNB\", \"\\n\")\n",
    "print(confusion_matrix(y_test, nb_clf.predict(X_test_vec), labels = [0,1,2,3,4]) -\n",
    "      confusion_matrix(y_test, svm_clf.predict(X_test_vec), labels = [0,1,2,3,4]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for MNB Model\n",
      "[0.39044402 0.47426233 0.67923154 0.51251876 0.44493882] \n",
      "\n",
      "Recall for MNB Model\n",
      "[0.28637168 0.40311213 0.76760452 0.48719874 0.31931879] \n",
      "\n",
      "Classification Report for MNB Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.29      0.33      2825\n",
      "           1       0.47      0.40      0.44     10925\n",
      "           2       0.68      0.77      0.72     31597\n",
      "           3       0.51      0.49      0.50     13319\n",
      "           4       0.44      0.32      0.37      3758\n",
      "\n",
      "    accuracy                           0.60     62424\n",
      "   macro avg       0.50      0.45      0.47     62424\n",
      "weighted avg       0.58      0.60      0.58     62424\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision, recall, and classification report for mnb\n",
    "print(\"Precision for MNB Model\")\n",
    "print(precision_score(y_test, nb_clf.predict(X_test_vec), average = None), \"\\n\")\n",
    "print(\"Recall for MNB Model\")\n",
    "print(recall_score(y_test, nb_clf.predict(X_test_vec), average = None), \"\\n\")\n",
    "print(\"Classification Report for MNB Model\")\n",
    "print(classification_report(y_test, nb_clf.predict(X_test_vec), target_names = [\"0\",\"1\",\"2\",\"3\",\"4\"]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for SVM Model\n",
      "[0.45940873 0.52018812 0.69631021 0.55363596 0.50151771] \n",
      "\n",
      "Recall for SVM Model\n",
      "[0.34654867 0.41510297 0.8212172  0.47158195 0.3956892 ] \n",
      "\n",
      "Classification Report for SVM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.35      0.40      2825\n",
      "           1       0.52      0.42      0.46     10925\n",
      "           2       0.70      0.82      0.75     31597\n",
      "           3       0.55      0.47      0.51     13319\n",
      "           4       0.50      0.40      0.44      3758\n",
      "\n",
      "    accuracy                           0.63     62424\n",
      "   macro avg       0.55      0.49      0.51     62424\n",
      "weighted avg       0.61      0.63      0.62     62424\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision, recall, and classification report for svm\n",
    "print(\"Precision for SVM Model\")\n",
    "print(precision_score(y_test, svm_clf.predict(X_test_vec), average = None), \"\\n\")\n",
    "print(\"Recall for SVM Model\")\n",
    "print(recall_score(y_test, svm_clf.predict(X_test_vec), average = None), \"\\n\")\n",
    "print(\"Classification Report for SVM Model\")\n",
    "print(classification_report(y_test, svm_clf.predict(X_test_vec), target_names = [\"0\",\"1\",\"2\",\"3\",\"4\"]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature ranks\n",
    "feature_ranks_very_neg_mnb = sorted(zip(nb_clf.feature_log_prob_[0], unigram_count_vectorizer.get_feature_names()))\n",
    "feature_ranks_very_pos_mnb = sorted(zip(nb_clf.feature_log_prob_[4], unigram_count_vectorizer.get_feature_names()))\n",
    "feature_ranks_very_neg_svm = sorted(zip(svm_clf.coef_[0], unigram_count_vectorizer.get_feature_names()))\n",
    "feature_ranks_very_pos_svm = sorted(zip(svm_clf.coef_[4], unigram_count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Indicative Words for Very Negative Category MNB Model \n",
      "\n",
      "[(-7.272981555830627, 'cloying'), (-7.107467117353054, 'anachronistic'), (-6.980311941867808, 'phrase'), (-6.854271220972443, 'retaliatory'), (-6.802977926584893, 'animals'), (-6.685194890928509, 'purists'), (-6.674145054741924, 'innocuous'), (-6.550275573029138, 'generosity'), (-5.560987055071435, 'confession'), (-5.511681294087281, 'undermining')] \n",
      "\n",
      "Top 10 Indicative Words for Very Negative Category SVM Model \n",
      "\n",
      "[(1.532896493786733, 'smash'), (1.5428904827358356, 'atypically'), (1.5638131694848745, 'proper'), (1.6406563014286202, 'predicament'), (1.6530806397243731, 'results'), (1.6983640253240764, 'meddles'), (1.706159275130978, 'stereotyped'), (1.7293156995789352, 'relevance'), (1.7771190757844315, 'complications'), (1.8892389955847735, 'precocious')]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 very negative for mnb and svm\n",
    "print(\"Top 10 Indicative Words for Very Negative Category MNB Model\", \"\\n\")\n",
    "print(feature_ranks_very_neg_mnb[-10: ], \"\\n\")\n",
    "print(\"Top 10 Indicative Words for Very Negative Category SVM Model\", \"\\n\")\n",
    "print(feature_ranks_very_neg_svm[-10: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Indicative Words for Very Positive Category MNB Model \n",
      "\n",
      "[(-6.957636910776074, 'floria'), (-6.957636910776074, 'tied'), (-6.9313196024587, 'reduce'), (-6.820777728058877, 'pork'), (-6.8092169056578005, 'veil'), (-6.753336447263344, 'generosity'), (-6.753336447263344, 'slasher'), (-6.264489730216129, 'innocuous'), (-5.798661472380873, 'defiance'), (-4.9347657205846325, 'undermining')] \n",
      "\n",
      "Top 10 Indicative Words for Very Positive Category SVM Model \n",
      "\n",
      "[(1.436821695395699, 'nuances'), (1.4574568221895732, 'landau'), (1.4623816688376123, 'operandi'), (1.498729931615342, 'complicated'), (1.5015474508026285, 'nephew'), (1.5265681411640997, 'startled'), (1.5775369722317834, 'suffocation'), (1.6072914745057028, 'blacks'), (1.759757468229615, 'start'), (1.8745669202066426, 'drowsy')]\n"
     ]
    }
   ],
   "source": [
    "# Top 10 very positive for mnb and svm\n",
    "print(\"Top 10 Indicative Words for Very Positive Category MNB Model\", \"\\n\")\n",
    "print(feature_ranks_very_pos_mnb[-10: ], \"\\n\")\n",
    "print(\"Top 10 Indicative Words for Very Positive Category SVM Model\", \"\\n\")\n",
    "print(feature_ranks_very_pos_svm[-10: ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "# **TASK 3 - BEST CLASSIFIER**\n",
    "\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the vectorization pipeline\n",
    "tfidf_pip = Pipeline([\n",
    "    (\"tfidf_vectorizer\", TfidfVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the naive bayes pipeline\n",
    "mnb_pipeline = Pipeline([\n",
    "    (\"tfidf_pip\", tfidf_pip),\n",
    "    (\"mnb\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the grid search params\n",
    "grid_params = {\n",
    "  \"mnb__alpha\": numpy.linspace(0.5, 1.5, 3),\n",
    "  'mnb__fit_prior': [True, False],\n",
    "  \"tfidf_pip__tfidf_vectorizer__use_idf\": [True, False],\n",
    "  \"tfidf_pip__tfidf_vectorizer__norm\": [None, \"l1\", \"l2\"], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.6019479717418196\n",
      "Test Score =  0.6081475073689606\n",
      "Best Params =  {'mnb__alpha': 1.5, 'mnb__fit_prior': True, 'tfidf_pip__tfidf_vectorizer__norm': None, 'tfidf_pip__tfidf_vectorizer__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "nb_clf = GridSearchCV(mnb_pipeline, grid_params)\n",
    "nb_clf.fit(X_train, y_train)\n",
    "predictions = nb_clf.predict(X_test)\n",
    "print(\"Train Score = \", nb_clf.best_score_)\n",
    "print(\"Test Score = \", accuracy_score(y_test, predictions))\n",
    "print(\"Best Params = \", nb_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit vectorizer and MNB with the params\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    norm = None,\n",
    "    use_idf = False\n",
    ")\n",
    "\n",
    "nb_clf = MultinomialNB(alpha = 1.5, fit_prior = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  1  Completed\n",
      "Test Score  0.6148276303985647\n",
      "Run  2  Completed\n",
      "Test Score  0.6138023836985774\n",
      "Run  3  Completed\n",
      "Test Score  0.6190567730360118\n",
      "Run  4  Completed\n",
      "Test Score  0.6099577085736255\n",
      "Run  5  Completed\n",
      "Test Score  0.6120082019736\n",
      "Run  6  Completed\n",
      "Test Score  0.6130334486735871\n",
      "Run  7  Completed\n",
      "Test Score  0.6090606177111367\n",
      "Run  8  Completed\n",
      "Test Score  0.6146994745610662\n",
      "Run  9  Completed\n",
      "Test Score  0.6084198385236448\n",
      "Run  10  Completed\n",
      "Test Score  0.6186723055235166\n"
     ]
    }
   ],
   "source": [
    "# Initiate the split object\n",
    "split = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Initiate a counter\n",
    "run_counter = 0\n",
    "\n",
    "# Iterate through each fold and conduct the process\n",
    "for train_index, test_index in split.split(data_train, data_train[\"Sentiment\"]):\n",
    "\n",
    "    # Seperate out the train and test sets\n",
    "    train_data = data_train.iloc[train_index, :]\n",
    "    test_data = data_train.iloc[test_index, :]\n",
    "    \n",
    "    # Separate out the predictors\n",
    "    X_train = train_data[\"Phrase\"]\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test = test_data[\"Phrase\"]\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Seperate out the class labels\n",
    "    y_train = train_data[\"Sentiment\"].copy()\n",
    "    y_test = test_data[\"Sentiment\"].copy()\n",
    "\n",
    "    # Train model and and make predictions\n",
    "    nb_clf.fit(X_train_vec, y_train)\n",
    "    predictions = nb_clf.predict(X_test_vec)\n",
    "\n",
    "    # Store the information from the run\n",
    "    test_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "    # Update the counter after each iteration\n",
    "    run_counter += 1\n",
    "\n",
    "    # Print out the results\n",
    "    print(\"Run \", run_counter, \" Completed\")\n",
    "    print(\"Test Score \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the vectorization pipeline\n",
    "tfidf_pip = Pipeline([\n",
    "    (\"tfidf_vectorizer\", TfidfVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the naive bayes pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"tfidf_pip\", tfidf_pip),\n",
    "    (\"svm\", LinearSVC(max_iter = 100000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the grid search params\n",
    "grid_params = {\n",
    "  \"svm__C\": numpy.linspace(1, 10, 3),\n",
    "  \"tfidf_pip__tfidf_vectorizer__use_idf\": [True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.629672306900651\n",
      "Test Score =  0.6347718826092529\n",
      "Best Params =  {'svm__C': 1.0, 'tfidf_pip__tfidf_vectorizer__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "svm_clf = GridSearchCV(svm_pipeline, grid_params)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "predictions = svm_clf.predict(X_test)\n",
    "print(\"Train Score = \", svm_clf.best_score_)\n",
    "print(\"Test Score = \", accuracy_score(y_test, predictions))\n",
    "print(\"Best Params = \", svm_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit vectorizer and SVM with the params\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf = False)\n",
    "\n",
    "svm_clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  1  Completed\n",
      "Test Score  0.6441112392669486\n",
      "Run  2  Completed\n",
      "Test Score  0.6433423042419583\n",
      "Run  3  Completed\n",
      "Test Score  0.6496219402793797\n",
      "Run  4  Completed\n",
      "Test Score  0.6423811354607203\n",
      "Run  5  Completed\n",
      "Test Score  0.6475714468794054\n",
      "Run  6  Completed\n",
      "Test Score  0.6477636806356529\n",
      "Run  7  Completed\n",
      "Test Score  0.6399461745482506\n",
      "Run  8  Completed\n",
      "Test Score  0.6455850313981802\n",
      "Run  9  Completed\n",
      "Test Score  0.6425092912982187\n",
      "Run  10  Completed\n",
      "Test Score  0.6496860181981289\n"
     ]
    }
   ],
   "source": [
    "# Initiate the split object\n",
    "split = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Initiate a counter\n",
    "run_counter = 0\n",
    "\n",
    "# Iterate through each fold and conduct the process\n",
    "for train_index, test_index in split.split(data_train, data_train[\"Sentiment\"]):\n",
    "\n",
    "    # Seperate out the train and test sets\n",
    "    train_data = data_train.iloc[train_index, :]\n",
    "    test_data = data_train.iloc[test_index, :]\n",
    "    \n",
    "    # Separate out the predictors\n",
    "    X_train = train_data[\"Phrase\"]\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test = test_data[\"Phrase\"]\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Seperate out the class labels\n",
    "    y_train = train_data[\"Sentiment\"].copy()\n",
    "    y_test = test_data[\"Sentiment\"].copy()\n",
    "\n",
    "    # Train model and and make predictions\n",
    "    svm_clf.fit(X_train_vec, y_train)\n",
    "    predictions = svm_clf.predict(X_test_vec)\n",
    "\n",
    "    # Store the information from the run\n",
    "    test_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "    # Update the counter after each iteration\n",
    "    run_counter += 1\n",
    "\n",
    "    # Print out the results\n",
    "    print(\"Run \", run_counter, \" Completed\")\n",
    "    print(\"Test Score \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle submission\n",
    "vectorizer = TfidfVectorizer(use_idf = False)\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_vec, y)\n",
    "X_kaggle = data_test.Phrase.copy()\n",
    "ids = data_test.PhraseId.copy()\n",
    "X_kaggle_vec = vectorizer.transform(X_kaggle)\n",
    "predictions = svm_clf.predict(X_kaggle_vec)\n",
    "submission = pandas.DataFrame(list(zip(\n",
    "    ids, predictions)), columns = [\"PhraseId\", \"Sentiment\"])\n",
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "837a5e7ae28b4e198c1d8cf4796a058d56e0b65e3e1483208ccae61f9a209f4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
